# -*- coding: utf-8 -*-
"""ml_experiment10_77.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nkI6TA7ZbBUEhVCyF06hItZoZBctC3Zs

# Naive Bayes classifier Algorithm

Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import seaborn as sns 
# %matplotlib inline

"""Loading dataset i.e. Adult dataset"""

df = pd.read_csv('adult.csv')
df.head()

df.shape

"""Rename column names"""

c_n = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',
             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']

df.columns = c_n

df.columns

df.head()

"""Declaring feature vector and target variable"""

X = df.drop(['income'], axis=1)

y = df['income']

"""Split X and y into training and testing sets"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

X_train.shape, X_test.shape

pip install --upgrade category_encoders

import category_encoders as ce

"""Encoding remaining variables with one-hot encoding"""

the_encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', 
                                 'race', 'sex', 'native_country'])

X_train = the_encoder.fit_transform(X_train)
X_test = the_encoder.transform(X_test)

X_train.head()

X_test.head()

"""Feature scaling"""

the_cols = X_train.columns

from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

X_train = pd.DataFrame(X_train, columns=[the_cols])

X_test = pd.DataFrame(X_test, columns=[the_cols])

X_train.head()

"""Model training
- Train a Gaussian Naive Bayes classifier on the training set
- instantiate the model
- fit the model
"""

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()

gnb.fit(X_train, y_train)

"""Predicting results"""

y_pred = gnb.predict(X_test)

y_pred

"""Checking model accuracy score"""

from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

print('Training set score: {:.4f}'.format(gnb.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(gnb.score(X_test, y_test)))

""" Checking class distribution in test set"""

y_test.value_counts()

"""Printing the Confusion Matrix and slicing it into four pieces"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)
print('\nTrue Positives(TP) = ', cm[0,0])
print('\nTrue Negatives(TN) = ', cm[1,1])
print('\nFalse Positives(FP) = ', cm[0,1])
print('\nFalse Negatives(FN) = ', cm[1,0])

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

TP = cm[0,0]
TN = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]

classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)

print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))

classification_error = (FP + FN) / float(TP + TN + FP + FN)

print('Classification error : {0:0.4f}'.format(classification_error))

precision = TP / float(TP + FP)

print('Precision : {0:0.4f}'.format(precision))